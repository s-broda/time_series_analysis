\input{../preamble.tex}
\institute{{\Large Volatility Modelling}}
\begin{document}
\frame{\titlepage}
\input{../weeks.tex}

\section{Introduction}\subsection*{bla}

\begin{frame}
\frametitle{Goal}
\begin{itemize}
\item Recall these stylized facts about asset returns:
\begin{enumerate}
\item Lack of autocorrelation (efficient market hypothesis)
\item Volatility clustering
\item Distribution has heavy tails
\item Leverage effects
\end{enumerate}
\item Goal today: model the last 3 of these, starting with the volatility clustering.
\end{itemize}
\end{frame}

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{Volatility}

\begin{itemize}
\item The \emph{\color{red}volatility} of an investment is a measure of its
\emph{\color{red}risk}. Usually defined as the standard deviation of the
return on the investment.

\item Volatility is an important ingredient in:

\begin{itemize}
\item portfolio selection;

\item risk management;

\item option pricing.
\end{itemize}

\item Daily financial returns display \emph{\color{red}volatility clustering}%
: periods of high volatility alternate with more tranquil periods.
\item In other words: large (in absolute value) returns tend to be
followed by large (in absolute value) returns.

\item This forms the basis for the \emph{\color{red}%
autoregressive-conditional heteroskedasticity} model (ARCH; Engle, 1982) and
the \emph{\color{red}generalized ARCH} model (GARCH; Bollerslev, 1986).
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

\begin{frame}
\begin{block}{Example: Daily Returns on Apple Stock}
\begin{center}
\begin{tabular}{cc}
\includegraphics[width=0.45\textwidth]{returns}&\includegraphics[width=0.45\textwidth]{kde}
\end{tabular}
\end{center}
\end{block}
\end{frame}
\frameit{Reminder: Parameters vs.\ sample values}{
\item We usually write $\sigma$ for the standard deviation of, e.g., a normally distributed variable.
\item $\sigma$ is a \er{parameter} and therefore unknown.
\item The best we can hope for is to \er{estimate} it, usually with the \er{sample standard deviation} $s$.
\item With stock returns, the standard deviation (or \er{volatility}) changes over time, due to \er{volatility clustering}.
\item We write $\sigma_t$ for the volatility in period $t$.
\item Note that $\sigma_t$ is \er{unobserved}. The best we can do is \er{estimate} it. We'll write $\widehat{\sigma}_t$ for this estimate.
\item Today, we'll mostly discuss different methods of estimation.
}
\frameit{Detecting Volatility Clustering (I)}{
\item Since volatility clustering means that large  returns tend to be followed by large returns, it is possible to detect it by inspecting the correlogram of the squared returns.
\end{itemize}
\begin{block}{Example: correlogram of squared S\&P500 returns.}
\begin{center}
\includegraphics[width=0.2\textwidth]{sp500corr_sq}
\end{center}
\end{block}
\begin{itemize}
\item Clearly, there is a lot of predictability in squared returns (unlike returns themselves).
}
\frameit{Detecting Volatility Clustering (II)}{
\item Besides relying on the $Q$-tests from the correlogram, another formal test is Engle's \er{ARCH-LM} test (essentially a Breusch-Godfrey test applied to the squared residuals).
\item EViews only offers it for residuals, not for a series itself. Hence, we start by regressing the returns on an intercept.
\item The ARCH-LM test is based on the auxiliary regression
\begin{equation*}
\hat{u}_{t}^{2}=\gamma _{0}+\gamma _{1}\hat{u}_{t-1}^{2}+\ldots +\gamma _{m}%
\hat{u}_{t-m}^{2}+e_{t}.
\end{equation*}
\item The lag length $m$ is chosen by the user, e.g., 5 for daily data.
\item The test statistic is $T\cdot R^2_{aux}$ and has a $\chi^2(m)$ distribution under  $H_0: \gamma_1=\cdots=\gamma_m=0$ (no volatility clustering).
}
\begin{frame}
\begin{block}{Example: ARCH-LM test for the S\&P500}
\begin{center}
\includegraphics[height=.6\textheight]{sp500_archlm}
\end{center}
\small The null of no volatility clustering is clearly rejected ($p$-value is zero, $T\cdot R^2_{aux}=948.96$ much larger than critical value 11.07).
\end{block}
\end{frame}
\section{Historical, RiskMetrics}\subsection*{}

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{Historical Volatility}

\begin{itemize}
\item A first simple estimator is \emph{\color{red}historical volatility},
i.e., the sample standard deviation of the most recent $m$ observations
(often $m=250$, one year).

\item If $r_{t}=\ln P_t-\ln P_{t-1}$ denotes the daily log-return, then
\begin{equation*}
\widehat{\sigma}_{t+1,HIST}^{2}=\frac{1}{m}\sum_{j=0}^{m-1}r_{t-j}^{2}.
\end{equation*}
(Typically the average return is relatively close to zero). This is an
estimate of the squared volatility over day $t+1$, made at the end of day $t$%
.

\item Main disadvantages:

\begin{itemize}
\item either noisy (small $m$), or reacts slowly to new information (large $%
m $);

\item \textquotedblleft ghosting\textquotedblright\ feature: large shock
leads to higher volatility for exactly $m$ periods, then drops out.
\end{itemize}
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{RiskMetrics}

\begin{itemize}
\item Problems with historical volatility are addressed by replacing equally
weigh\-ted moving average by an \emph{\color{red}exponentially} weighted
moving average (EWMA), also used in JPMorgan's \emph{\color{red}RiskMetrics}
system:%
\begin{eqnarray*}
\widehat{\sigma}_{t+1,EWMA}^{2}  &=&(1-\lambda )\sum_{j=0}^{\infty }\lambda
^{j}r_{t-j}^{2} \\
&=&\lambda\widehat{\sigma}_{t,EWMA}^{2}+(1-\lambda )r_{t}^{2},\qquad 0<\lambda <1.
\end{eqnarray*}
\item This means that observations further in the past get a smaller weight.

\item In practice we do not have $r_{t-\infty }$, but the second equation
can be started up by an initial estimate / guess $\sigma _{0,EWMA}^{2}$.
\item The larger $\lambda$, the stronger the persistence of shocks (large returns).
\item For daily data, RiskMetrics recommends $\lambda =0.94$.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: S\&P500 volatility, historical and EWMA ($\lambda = 0.8,0.94,0.99$)}
\begin{tabular}{cc}
\includegraphics[width=.4\textwidth]{historical}&
\includegraphics[width=.4\textwidth]{EWMA08}\\
\includegraphics[width=.4\textwidth]{EWMA94}&
\includegraphics[width=.4\textwidth]{EWMA99}
\end{tabular}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion
\section[ARCH/GARCH]{The ARCH and GARCH Models}\subsection*{}
%\begin{frame}\frametitle{Conditional Expectation}
%\begin{itemize}
%\item We use the notation $E_t[r_{t+1}]$ to denote the \er{conditional expectation} of $r_{t+1}$, given information up to time $t$.
%\item With this, the AR(1) model $Y_{t}=\mu +\phi Y_{t-1}+u_{t}$ can be formulated as
%\[
%E_{t}(Y_{t+1})=\mu +\phi Y_{t}.
%\]
%\item We also write $\sigma_{t+1}$ for the conditional volatility:
%\[
%\sigma_{t+1}=\sqrt{\text{var}_{t}(r_{t+1})}.
%\]
%\item Note that if $E_{t}(r_{t+1})=0$, then $\sigma_{t+1}^2=E_{t}(r_{t+1}^{2})$.
%\end{itemize}
%\end{frame}


\begin{frame}%
\frametitle{The ARCH Model}
\begin{itemize}
\item The first-order \emph{\color{red}%
autoregressive-conditional heteroskedasticity} (ARCH(1))  model, due to Engle (1982), for a return $%
r_{t}$ with mean zero is
\begin{equation*}
\sigma^2_{t+1}=\omega +\alpha r_{t}^{2}.
\end{equation*}
\item In practice, we need to allow for $\E[r_{t+1}]=\mu _{t+1}\neq 0.$
Then $r_{t+1}=\mu _{t+1}+u_{t+1}$, and the model becomes
\begin{equation*}
\sigma _{t+1}^{2}=\omega +\alpha
u_{t}^{2}.
\end{equation*}
\end{itemize}
\end{frame}%

\begin{frame}%
\frametitle{The ARCH Model}

\begin{itemize}
\item When trying to estimate ARCH models one might find that more lags are
needed, leading to ARCH($q$):%
\begin{equation*}
\sigma _{t+1}^{2}=\omega +\alpha _{1}u_{t}^{2}+\ldots +\alpha
_{q}u_{t-q+1}^{2}.
\end{equation*}

\item \emph{Note}: Variances must be positive, therefore we need to impose $%
\omega >0$, $\alpha _{i}\geq 0$, $i=1,\ldots ,q$.
\item It can be shown that an ARCH($q$) models corresponds to an AR($q$) for the squared returns. Thus, we could determine the order from the correlogram of the squared returns: SPACF should cut off after $q$ lags.
\item In the example above, we might conclude that we need an ARCH(6) model.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{The GARCH Model}

\begin{itemize}
\item A simpler structure than ARCH($q$) is an ARMA(1,1) for $r_{t}^{2}$ or $%
u_{t}^{2}$, which leads to the \emph{\color{red}generalized ARCH} model of
orders (1,1) \linebreak(GARCH(1,1)), due to Bollerslev (1986):
\begin{equation*}
\sigma _{t+1}^{2}=\omega +\alpha u_{t}^{2}+\beta \sigma _{t}^{2},\qquad
\omega >0,\alpha \geq 0,\beta \geq 0.
\end{equation*}

%\item For $\beta <1$ this is equivalent to an ARCH($\infty $) model
%\begin{equation*}
%\sigma _{t+1}^{2}=\frac{\omega }{1-\beta }+\sum_{j=0}^{\infty }\beta
%^{j}\alpha u_{t-j}^{2}.
%\end{equation*}

\item \emph{Advantage}: Flexible structure with only 3 parameters
to estimate.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{The GARCH Model}

\begin{itemize}
\item The GARCH(1,1) model is stationary if the unconditional (``average'') variance $%
\sigma ^{2}=\E[\sigma _{t}^{2}]$ is positive, constant and
finite.

\item This requires%
\begin{eqnarray*}
\sigma ^{2}=\E[\sigma _{t+1}^{2}] &=&\omega +\alpha \E[u_{t}^{2}]+\beta
\E[\sigma _{t}^{2}] \\
&=&\omega +\alpha \sigma ^{2}+\beta \sigma ^{2}.
\end{eqnarray*}

\item Hence, provided that $\alpha +\beta <1$ (the \emph{\color{red}%
stationarity condition}),%
\begin{equation*}
\sigma ^{2}=\frac{\omega }{1-\alpha -\beta }.
\end{equation*}

\item The nonstationary model with $\alpha +\beta =1$ is called \emph{%
\color{red}integrated GARCH} (IGARCH): infinite variance, no mean-reversion
in volatility.

\item Notice that an IGARCH with $r_{t}=u_{t}$, $\omega =0$, $\beta=\lambda$, and $\alpha=(1-\lambda)$ is just the RiskMetrics model.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{The GARCH Model}

Some other properties:

\begin{itemize}
\item The ACF and PACF of $r_{t}^{2}$ in case of stationary GARCH(1,1) are
both exponentially decaying, no cut-off point.

\item The \emph{\color{red}standardized returns}
\begin{equation*}
z_{t+1}=\frac{r_{t+1}-\mu _{t+1}}{\sigma _{t+1}}
\end{equation*}%
satisfy $E(z_{t+1})=0$ and $\text{var}(z_{t+1})=1$. Therefore the
model may be formulated as%
\begin{eqnarray*}
r_{t+1} &=&\mu _{t+1}+u_{t+1}=\mu _{t+1}+\sigma _{t+1}z_{t+1}, \\
\sigma _{t+1}^{2} &=&\omega +\alpha u_{t}^{2}+\beta \sigma _{t}^{2}.
\end{eqnarray*}

\item Often it is assumed that $z_{t}$ are i.i.d. as $N(0,1)$.

\item Even if $z_{t}\sim N(0,1)$, it can be shown that varying $\sigma _{t}$
implies that $r_{t}$ has non-normal distribution, with higher kurtosis.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{The GARCH($p$, $q$) Model}

\begin{itemize}
\item The GARCH(1, 1) model can be extended to the GARCH($p$, $q$) model
\begin{equation*}
\sigma _{t+1}^{2}=\omega +\alpha_1 u_{t}^{2}+\cdots+\alpha_q u_{t-q+1}^{2} +\beta_1 \sigma _{t}^{2}+\cdots+\beta_p \sigma _{t-p+1}^{2}
\end{equation*}
 although in practice, this is rarely necessary.
\item The model is stationary if $\sum_{i=1}^p\beta_i+\sum_{i=1}^q\alpha_i<1$, and the unconditional variance is
\[
\frac{\omega}{1-\sum_{i=1}^p\beta_i-\sum_{i=1}^q\alpha_i}.
\]

\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

\section[Estimation]{Estimation of GARCH Models}\subsection*{}
%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{Estimation of GARCH Models}

\begin{itemize}
\item GARCH cannot be estimated by ordinary least-squares (because
$\sigma^2_t$ is not observed).

\item Such models are estimated by \emph{\color{red}maximum likelihood}: the
joint density of the observations $\{r_{1},\ldots ,r_{T}\}$ is maximized
with respect to the parameters.

\item Maximization of $\log L$ can be done by numerical optimization
algorithms. By default, EViews does this under the assumption of normality.

\item If we are not sure that the $z_{t}$'s are normally distributed, then
we may still use the same estimation technique. This is called \emph{%
\color{red}quasi-maximum likelihood estimator}.

\item However, we need to construct standard errors via a more robust method
(\emph{\color{red}Bollerslev-Wooldridge standard errors}).
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: EViews output, estimated GARCH model for S\&P500}
\centerline{\includegraphics[height=1.7in]{sp500_garch}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: Estimated GARCH volatility of S\&P500}
\centerline{\includegraphics[height=1.7in]{sp500_sigmas}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion
\section[Testing]{Testing GARCH\ Models}\subsection*{}
%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{Testing GARCH Models}

\begin{itemize}
\item Diagnostic tests are based on the \emph{\color{red}standardized
residuals} $\hat{z}_{t}:=\hat{u}_{t}/\hat{\sigma}_{t}$. If $\mu _{t}$ and $%
\sigma _{t}$ are correctly specified, we should find no autocorrelation in $%
\hat{z}_{t}$ and $\hat{z}_{t}^{2}$.

\item Therefore, the model can be tested using $Q$-statistics for $\hat{z}%
_{t}$ or $\hat{z}_{t}^{2}$.

\item Lagrange-Multiplier (LM) test against ARCH, which is obtained by $%
T\cdot R^{2}$ in the regression%
\begin{equation*}
\hat{z}_{t}^{2}=\gamma _{0}+\gamma _{1}\hat{z}_{t-1}^{2}+\ldots +\gamma _{m}%
\hat{z}_{t-m}^{2}+e_{t}.
\end{equation*}

\item To test for normality of $z_{t}$, we can use the Jarque-Bera test
based on the skewness and kurtosis of $\hat{z}_{t}$.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: Correlogram of standardized residuals for the S\&P500}
\centerline{\includegraphics[height=1.7in]{corr_resids}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: Correlogram of squared standardized residuals for the S\&P500}
\centerline{\includegraphics[height=1.7in]{corr_resids_sq}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: Normality test of standardized residuals for the S\&P500}
\centerline{\includegraphics[height=1.7in]{hist_resids}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion


\section[Asymmetry]{Asymmetry and the News Impact Curve}\subsection*{}
%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{Asymmetry and the News Impact Curve}

\begin{itemize}
\item The \emph{\color{red}news impact curve} (NIC) is the effect of $u_{t}$
on $\sigma _{t+1}^{2}$, keeping $\sigma _{t}^{2}$ and the past fixed.

\item For GARCH(1,1), this is the parabola $NIC(u_{t}|\sigma _{t}^{2}=\sigma
^{2})=A+\alpha u_{t}^{2}$, with $A=\omega +\beta \sigma ^{2}$. This has a
minimum at $u_{t}=0$, and is symmetric around that minimum.

\item For equity, a large negative shock is expected to
increase volatility more than a large positive shock,
because of \emph{\color{red}leverage effect}:
\begin{tabbing}
\hspace{4ex} \= $\downarrow$ \=value of firm's stock \\
$\Rightarrow$ \> $\downarrow$ \> equity value of the firm \\
$\Rightarrow$ \> $\uparrow$ \> debt-to-equity ratio \\
$\Rightarrow$ \> shareholders (as residual claimants) perceive future cashflows\\
\> as more risky.
\end{tabbing}

\item Two popular proposals to deal with this issue:

\begin{itemize}
\item Nelson's exponential GARCH (EGARCH);

\item Glosten, Jagannathan and Runkle's GJR-GARCH.
\end{itemize}
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{GJR-GARCH (or TARCH, threshold GARCH)}

The GJR-GARCH(1,1) model is%
\begin{equation*}
\sigma _{t+1}^{2}=\omega +\alpha u_{t}^{2}+\gamma u_{t}^{2}\text{I}%
_{t}+\beta \sigma _{t}^{2}.
\end{equation*}%
where%
\begin{equation*}
\text{I}_{t}=\left\{
\begin{array}{ccc}
1 & \text{if} & u_{t}<0 \\
0 & \text{if} & u_{t}\geq 0%
\end{array}%
\right. ,
\end{equation*}%
and $u_{t}/\sigma_{t}$ has a symmetric distribution.

Properties:

\begin{itemize}
\item NIC is asymmetric if and only if $\gamma \neq 0$; leverage effect if $%
\gamma >0$;

\item $\sigma _{t}^{2}$ is positive if $\omega >0$, $\alpha \geq 0$, $\gamma
\geq 0$, $\beta \geq 0$;

\item $u_{t}^{2}$ is stationary if $0\leq \alpha +\frac{1}{2}\gamma +\beta
<1 $, with unconditional variance $\sigma ^{2}=\omega /\left[ 1-\alpha -%
\frac{1}{2}\gamma -\beta \right] $.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansiom

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\frametitle{EGARCH}

The EGARCH(1,1) model is%
\begin{equation*}
\log \sigma _{t+1}^{2}=\omega +\gamma z_{t}+\alpha (\left\vert
z_{t}\right\vert -E\left\vert z_{t}\right\vert )+\beta \log \sigma _{t}^{2},
\end{equation*}%
with $z_{t}=u_{t}/\sigma _{t}$ as usual. If $z_{t}\sim \text{i.i.d.}~N(0,1) $
then $E\left\vert z_{t}\right\vert =\sqrt{2/\pi }$.

Properties:

\begin{itemize}
\item NIC is asymmetric if and only if $\gamma \neq 0$; leverage effect if $%
\gamma <0$;

\item $\sigma _{t}^{2}$ is positive for all parameter values;

\item $\gamma z_{t}+\alpha (\left\vert z_{t}\right\vert -E\left\vert
z_{t}\right\vert )$ is an i.i.d.~mean-zero shock to log-volatility;

\item if $\left\vert \beta \right\vert <1$, $\log \sigma _{t}^{2}$
is\thinspace stationary with mean $\omega /(1-\beta )$.
\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion


%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: EViews output, estimated TARCH model for S\&P500}
\centerline{\includegraphics[height=1.7in]{sp500_gjr}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion

%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}%
%EndExpansion

\begin{block}{Example: NIC of GARCH and TARCH models for S\&P500}
\centerline{\includegraphics[height=2.5in]{NIC}}
\end{block}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion
%\section{GARCH-in-Mean}\subsection*{}
%%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%%BeginExpansion
%\begin{frame}%
%%EndExpansion
%
%\frametitle{GARCH-in-Mean}
%
%\begin{itemize}
%\item Asset pricing models (CAPM, APT) imply that investors expect a higher
%return for taking additional risks.
%
%\item We can model this by letting the expected return depend on the risk.
%This leads to
%\begin{eqnarray*}
%r_{t+1} &=&\mu +\delta \sigma _{t+1}^{2}+u_{t+1}, \\
%\sigma _{t+1}^{2} &=&\omega +\alpha u_{t}^{2}+\beta \sigma _{t}^{2}.
%\end{eqnarray*}%
%known as \emph{\color{red}GARCH-in-Mean} (GARCH-M) model.
%
%\item If $\delta >0,$ then $\uparrow \sigma _{t+1}^{2}\Rightarrow \uparrow
%E_{t}(r_{t+1})$; thus $\delta $ can be interpreted as a risk premium.
%\item According to the CAPM, idiosyncratic risk is not priced. Hence this model is useful only for index returns.
%\item Even for indices, empirical evidence for GARCH-in-mean is typically weak.
%\end{itemize}
%
%%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%%BeginExpansion
%\end{frame}%
%%EndExpansion
\section[Forecasting]{Volatility Forecasting}\subsection*{}
%TCIMACRO{\TeXButton{BeginFrame}{\begin{frame}}}%
%BeginExpansion
\begin{frame}
%EndExpansion

\frametitle{Volatility Forecasting}

\begin{itemize}
\item GARCH models directly provide forecasts of next day's volatility:
\[
\widehat{\sigma} _{t+1}^{2}=\hat{\omega}+\hat{\alpha}\hat{u}_{t}^{2}+\hat{\beta} \widehat{\sigma} _{t}^{2}.
\]

\item This can also be
expressed as
\[
\widehat{\sigma} _{t+1}^{2}=\widehat{\sigma}^2+\hat{\alpha}(\hat{u}_{t}^{2}-\widehat{\sigma}^2)+\hat{\beta} (\widehat{\sigma} _{t}^{2}-\widehat{\sigma}^2).
\]
with $\widehat{\sigma}^2=\hat{\omega} /(1-\hat\alpha -\hat\beta )$; see the exercises.

\item So the forecast differs from
the average variance $\widehat{\sigma} ^{2}$ if $\hat{u}_{t}^{2}$ or $\widehat{\sigma}
_{t}^{2}$ differ from $\widehat{\sigma} ^{2}$.

\end{itemize}

%TCIMACRO{\TeXButton{EndFrame}{\end{frame}}}%
%BeginExpansion
\end{frame}%
%EndExpansion
\frameit{Multi-Period Forecasts}{
\item Regarding multi-period forecasts of the stationary GARCH(1, 1) model, it can be shown that
\[
\widehat{\sigma} _{t+s}^{2}=\widehat{\sigma} ^{2}+(\hat\alpha+\hat\beta)^{s-1} (\widehat{\sigma}_{t+1}^{2}-\widehat{\sigma} ^{2}),
\]
see the exercises.
\item This implies $\widehat{\sigma} _{t+s}^{2}\rightarrow \widehat{\sigma} ^{2}$ as $%
s\rightarrow \infty $.

\item For RiskMetrics ($\alpha +\beta =1$, $\omega =0$), this simplifies to $\widehat{\sigma} _{t+s}^{2}=\widehat{\sigma}_{t+1}^{2}$ for
all $s$.
}
\section{Epilogue}\subsection*{bla}
\begin{frame}\frametitle{Learning Goals}
Students
\begin{itemize}
\item can use appropriate tests to detect volatility clustering,
\item are able to estimate, interpret, and forecast the various models (historical volatility, RiskMetrics, (G)ARCH, TARCH, EGARCH),
and to apply diagnostic tests to the standardized residuals,
\item and understand the concept of leverage, and the NIC.

\end{itemize}

\end{frame}

\frameit{Homework}{
\item Exercise 5
\item Questions 1 and 3 from Chapter 9 of Brooks (2019)
}


\end{document}
